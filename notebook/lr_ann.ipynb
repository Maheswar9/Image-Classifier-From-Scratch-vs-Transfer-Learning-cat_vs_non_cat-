{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c66924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "#loading the dataset\n",
    "train_dataset = h5py.File('../data/train_catvsnoncat.h5', \"r\")\n",
    "test_dataset = h5py.File('../data/test_catvsnoncat.h5', \"r\")\n",
    "\n",
    "print(\"File format of train_dataset:\",train_dataset)\n",
    "print(\"File format of test_dataset:\",test_dataset)\n",
    "\n",
    "# Load training data\n",
    "train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # train set features\n",
    "train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # train set labels\n",
    "\n",
    "# Load test data\n",
    "test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # test set features\n",
    "test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # test set labels\n",
    "#split the data\n",
    "validation_x = test_set_x_orig[:25] \n",
    "validation_y = test_set_y_orig[:25]\n",
    "print(\"Validation data shape: \",validation_x.shape)\n",
    "\n",
    "test_set_x = test_set_x_orig[25:]\n",
    "test_set_y = test_set_y_orig[25:]\n",
    "print(\"Test data shape: \",test_set_x.shape)\n",
    "\n",
    "m_train = np.squeeze(train_set_y_orig.shape) \n",
    "m_val = np.squeeze(validation_y.shape)\n",
    "m_test = np.squeeze(test_set_y.shape)\n",
    "num_px = train_set_x_orig.shape[1]\n",
    "\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"Number of validation examples: m_val = \" + str(m_val))\n",
    "print (\"Number of testing examples: m_test = \" + str(m_test))\n",
    "print (\"Height/Width of each image: num_px = \" + str(num_px))\n",
    "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "#exploring the data\n",
    "classes = np.array(test_dataset[\"list_classes\"][:])\n",
    "\n",
    "print(\"Classes are: \",classes)\n",
    "print(\"Groundtruth stored as: \",train_set_y_orig[2])\n",
    "print(classes[train_set_y_orig[2]].decode('utf-8'))\n",
    "\n",
    "plt.imshow(train_set_x_orig[2])\n",
    "#shape of the data\n",
    "print(\"train_set_x shape: \", train_set_x_orig.shape)\n",
    "print(\"train_set_y shape: \", train_set_y_orig.shape)\n",
    "\n",
    "print(\"Validation data size: \",validation_x.shape)\n",
    "print(\"Validation data size: \", validation_y.shape)\n",
    "\n",
    "print(\"test_set_x shape: \", test_set_x.shape)\n",
    "print(\"test_set_y shape: \", test_set_y.shape)\n",
    "#reshaping the data\n",
    "train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T\n",
    "validation_x_flatten = validation_x.reshape(validation_x.shape[0], -1).T\n",
    "test_set_x_flatten = test_set_x.reshape(test_set_x.shape[0], -1).T\n",
    "\n",
    "print (\"train_set_x_flatten shape: \", train_set_x_flatten.shape)\n",
    "print (\"train_set_y shape: \", train_set_y_orig.shape)\n",
    "\n",
    "print (\"validation_x_flatten shape: \", validation_x_flatten.shape)\n",
    "print (\"validation_y shape: \", validation_y.shape)\n",
    "\n",
    "print (\"test_set_x_flatten shape: \", test_set_x_flatten.shape)\n",
    "print (\"test_set_y shape: \", test_set_y.shape)\n",
    "\n",
    "\n",
    "#feature scaling\n",
    "print(\"Original Min value: \",train_set_x_flatten.reshape(1,-1).min())\n",
    "print(\"Original Max value: \",train_set_x_flatten.reshape(1,-1).max())\n",
    "\n",
    "train_set_x = train_set_x_flatten / 255.\n",
    "validation_set_x = validation_x_flatten / 255.\n",
    "test_set_x = test_set_x_flatten / 255.\n",
    "\n",
    "print(\"Standardized Min value: \",train_set_x.reshape(1,-1).min())\n",
    "print(\"Standardized Max value: \",train_set_x.reshape(1,-1).max())\n",
    "#defining the utility functions\n",
    "def sigmoid(z):\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    return s\n",
    "\n",
    "z = np.linspace(-10,10,2000000) \n",
    "sigmoid_z = sigmoid(z)\n",
    "\n",
    "plt.plot(z, sigmoid_z) \n",
    "plt.xlabel(\"z\") \n",
    "plt.ylabel(\"Sigmoid(z)\") \n",
    "plt.show()\n",
    "#initializing the weights\n",
    "def initialize_weights(dim):\n",
    "    np.random.seed(0)\n",
    "    w = np.random.rand(dim, 1)\n",
    "    b = 0    \n",
    "    return w, b\n",
    "\n",
    "\n",
    "dim = 2\n",
    "w, b = initialize_weights(dim)\n",
    "\n",
    "print(\"Weights: \",w)\n",
    "print(\"Biases: \", b)\n",
    "#forward propagation\n",
    "x = [1,2,3]\n",
    "x_log = np.log(x)\n",
    "\n",
    "a = np.array([[1,2],[3,4]]) \n",
    "b = np.array([[10,20],[30,40]]) \n",
    "\n",
    "c = np.dot(a,b)\n",
    "\n",
    "ones_array = np.ones(shape=(4,4))\n",
    "sum_of_ones_array = np.sum(ones_array)\n",
    "\n",
    "\n",
    "\n",
    "def forward_prop(w, b, X, Y):\n",
    "\n",
    "    # calculate activations\n",
    "    z = np.dot(w.T, X) + b\n",
    "    A = sigmoid(z)\n",
    "\n",
    "    # calculate cost\n",
    "    m = X.shape[1]\n",
    "    cost = (-1/m) * np.sum(Y * np.log(A) + (1-Y) * (np.log(1-A)))\n",
    "    cost = np.squeeze(cost)\n",
    "\n",
    "    return A, cost\n",
    "\n",
    "\n",
    "#backward propagation\n",
    "def back_prop(X, A, Y):\n",
    "\n",
    "    # calculate gradients for w,b\n",
    "    m = X.shape[1]\n",
    "    dw = (1/m) * np.dot(X, (A-Y).T)\n",
    "    db = (1/m) * np.sum(A-Y)\n",
    "\n",
    "    grads = {'dw': dw, 'db': db}\n",
    "\n",
    "    return grads\n",
    "#propagate\n",
    "def propagate(w, b, X, Y):\n",
    "\n",
    "    #Forward propagation\n",
    "    A, cost = forward_prop(w, b, X, Y)\n",
    "\n",
    "    #Backward propagation\n",
    "    grads = back_prop(X, A, Y)\n",
    "\n",
    "    return grads, cost\n",
    "\n",
    "w, b, X, Y = np.array([[1], [2]]), 2, np.array([[1,2], [3,4]]), np.array([[1, 0]])\n",
    "grads, cost = propagate(w, b, X, Y)\n",
    "#predict\n",
    "def predict(w, b, X):\n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1, m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "\n",
    "    #Compute probability vector\n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "\n",
    "    for i in range(A.shape[1]):\n",
    "        Y_prediction[0, i] = 1 if A[0, i] > 0.5 else 0\n",
    "\n",
    "    return Y_prediction\n",
    "#getting the accuracy\n",
    "y_actual = np.array([1,1,1,0,1])\n",
    "print(\"y_actual :\", y_actual )\n",
    "\n",
    "y_predicted = np.array([1,0,0,0,1])\n",
    "print(\"y_predicted :\", y_predicted )\n",
    "\n",
    "c = np.abs(y_actual  - y_predicted )\n",
    "print(\"c:\", c)\n",
    "\n",
    "c_mean = np.mean(c)\n",
    "print(\"c_mean:\", c_mean)\n",
    "\n",
    "acc = 100 - (c_mean * 100)\n",
    "print(\"acc:\", acc)\n",
    "\n",
    "def get_accuracies(Y_predicted, Y_actual):\n",
    "    abs_diff = np.abs(Y_predicted - Y_actual)\n",
    "    accuracy = 100 - np.mean(abs_diff) * 100\n",
    "    return accuracy\n",
    "#optimization\n",
    "def optimize(w, b, X, Y, X_val, Y_val, num_iterations, learning_rate):\n",
    "    prev_train_acc=0\n",
    "    prev_val_acc=0\n",
    "    costs=[]\n",
    "    epoch=0\n",
    "    final_w = w\n",
    "    final_b = b\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "\n",
    "        #Cost and gradient calculation\n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        costs.append(cost)\n",
    "        #Get derivatives\n",
    "        dw = grads['dw']\n",
    "        db = grads['db']\n",
    "\n",
    "        #Update rule\n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "\n",
    "        # Predict labels for train and validation sets        \n",
    "        Y_prediction_train = predict(w, b, X)\n",
    "        Y_prediction_val = predict(w, b, X_val)\n",
    "\n",
    "        # Get accuracies for the train and validation predictions\n",
    "        train_acc = get_accuracies(Y_prediction_train, Y)\n",
    "        val_acc = get_accuracies(Y_prediction_val, Y_val)\n",
    "\n",
    "        if val_acc > prev_val_acc and train_acc>=val_acc:\n",
    "            print(\"*****************************\")\n",
    "            print(\"Epoch - {} - train accuracy: {} %\".format(i,train_acc))\n",
    "            print(\"Epoch - {} - val accuracy: {} %\".format(i,val_acc))\n",
    "            print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            prev_train_acc = train_acc\n",
    "            prev_val_acc = val_acc\n",
    "            epoch = i\n",
    "            final_w = w\n",
    "            final_b = b\n",
    "\n",
    "    params = {'w': w, 'b': b}\n",
    "    grads = {'dw': dw, 'db': db}\n",
    "\n",
    "    optimal_values = {\n",
    "        'costs': costs,\n",
    "        'final w':final_w,\n",
    "        'final b':final_b,\n",
    "        'epoch':epoch,\n",
    "        'Train accuracy':prev_train_acc,\n",
    "        'Validation accuracy': prev_val_acc,\n",
    "        'Y_prediction_val': Y_prediction_val,\n",
    "         'Y_prediction_train': Y_prediction_train,\n",
    "         'params':params,\n",
    "         'grads':grads,\n",
    "    }\n",
    "\n",
    "    return optimal_values\n",
    "#model\n",
    "def model(X_train, Y_train, X_val, Y_val, num_iterations=2000, learning_rate=[0.5]):\n",
    "    prev_train_acc=0\n",
    "    prev_val_acc=0\n",
    "\n",
    "    # Initialize weights and bias\n",
    "    w, b = initialize_weights(X_train.shape[0])\n",
    "\n",
    "    best_values = {\n",
    "        'final w':w,\n",
    "        'final b':b,\n",
    "        'Train accuracy':prev_train_acc,\n",
    "        'Validation accuracy': prev_val_acc,\n",
    "     }\n",
    "\n",
    "\n",
    "    for lr in learning_rate:\n",
    "        print((\"-\"*30 + \"learning_rate:{}\"+\"-\"*30).format(lr))\n",
    "       # Initialize weights and bias\n",
    "        w, b = initialize_weights(X_train.shape[0])\n",
    "\n",
    "\n",
    "        # Optimization\n",
    "        lr_optimal_values = optimize(w, b, X_train, Y_train, X_val, Y_val, num_iterations, lr)\n",
    "        if lr_optimal_values['Validation accuracy']>prev_val_acc:\n",
    "            prev_val_acc = lr_optimal_values['Validation accuracy']\n",
    "            prev_train_acc = lr_optimal_values['Train accuracy']\n",
    "            final_lr = lr\n",
    "            final_w = lr_optimal_values['final w']\n",
    "            final_b = lr_optimal_values['final b']\n",
    "            final_epoch = lr_optimal_values['epoch']\n",
    "            final_Y_prediction_val = lr_optimal_values['Y_prediction_val']\n",
    "            final_Y_prediction_train = lr_optimal_values['Y_prediction_train']\n",
    "\n",
    "    best_values['Train accuracy'] = prev_train_acc\n",
    "    best_values['Validation accuracy'] = prev_val_acc\n",
    "    best_values['final_lr'] = final_lr\n",
    "    best_values['final w'] = final_w\n",
    "    best_values['final b'] = final_b\n",
    "    best_values['epoch'] = final_epoch\n",
    "    best_values['Y_prediction_val'] = final_Y_prediction_val\n",
    "    best_values['Y_prediction_train'] = final_Y_prediction_train\n",
    "\n",
    "    return best_values\n",
    "#training the model \n",
    "best_values = model(train_set_x, train_set_y_orig, validation_set_x, validation_y, num_iterations = 2000, learning_rate = [0.1,0.0001,0.001,0.005])\n",
    "#evaluating the model\n",
    "Y_prediction_test = predict(best_values['final w'], best_values['final b'], test_set_x)\n",
    "\n",
    "test_acc = get_accuracies(test_set_y, Y_prediction_test)\n",
    "print(\"Test accuracy is: \",test_acc)\n",
    "\n",
    "print(\"Final best model:\")\n",
    "print(\"For Learning rate:\" ,best_values['final_lr'], \", Epoch - \",best_values['epoch'])\n",
    "print(\"Train accuracy: \", best_values['Train accuracy'])\n",
    "print(\"Validation accuracy: \",best_values['Validation accuracy'])\n",
    "print(\"Test accuracy is: \",test_acc)\n",
    "# Correctly classified cat image\n",
    "plt.imshow(test_set_x[:,1].reshape((num_px, num_px, 3)))\n",
    "predicted_value = Y_prediction_test[0][1]\n",
    "print(\"Predicted as:\",classes[int(predicted_value)].decode('utf-8'))\n",
    "predicted_value\n",
    "\n",
    "# Correctly classified non-cat image\n",
    "plt.imshow(test_set_x[:,2].reshape((num_px, num_px, 3)))\n",
    "predicted_value = Y_prediction_test[0][2]\n",
    "print(\"Predicted as:\",classes[int(predicted_value)].decode('utf-8'))\n",
    "predicted_value\n",
    "\n",
    "# Incorrectly classified cat image\n",
    "plt.imshow(test_set_x[:,3].reshape((num_px, num_px, 3)))\n",
    "predicted_value = Y_prediction_test[0][3]\n",
    "print(\"Predicted as:\",classes[int(predicted_value)].decode('utf-8'))\n",
    "predicted_value\n",
    "\n",
    "# Incorrectly classified non-cat image\n",
    "plt.imshow(test_set_x[:,4].reshape((num_px, num_px, 3)))\n",
    "predicted_value = Y_prediction_test[0][4]\n",
    "print(\"Predicted as:\",classes[int(predicted_value)].decode('utf-8'))\n",
    "predicted_value\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
